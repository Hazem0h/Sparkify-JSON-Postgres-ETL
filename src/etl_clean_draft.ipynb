{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our objective in a nutshell\n",
    "We have some data scattered around in JSON files. We want to reorganise and store it in a relational database.\n",
    "\n",
    "## What is ETL?\n",
    "ETL stands for (Extract, Transform, and Load). The essence is \n",
    "* We have a datasource (in our case the JSON files), from which we want to *extract* the data **(*Extract*)**\n",
    "* We can then do some preprocessing (this can be doing calculations, or changing the format of some data, ...) **(*Transform*)**\n",
    "* Then, we load the data into some destination (in our case, the postgres Database) **(*Load*)**\n",
    "\n",
    "<center> <img src = \"../images/ETL-JSON-PG.jpg\" width = 500></center>\n",
    "\n",
    "\n",
    "## How will we do it?\n",
    "Using python, we can \n",
    "* Read the JSON files (Extract)\n",
    "* Do our preprocessing (Transform)\n",
    "* Interact with the database, using a database driver directly, like (psycopg2), or using a driver, with an object relational Model (ORM) like sqlalchemy\n",
    "<center> <img src = \"../images/ETL-with-python.jpg\" width = 50%></center>\n",
    "\n",
    "\n",
    "## What's our data about?\n",
    "Our data is a simulation of a music streaming app. The JSON files are split into two directores,\n",
    "* One directory `song_data` holds json files about our songs, like the song title, the artist, ...\n",
    "* The other directory `log_data` holds json files about Which songs were played, by whom, and at what time instances.\n",
    "\n",
    "This can be shown in the following image:\n",
    "<center><img src = \"../images/json-data-content.jpg\" width = 50%></center>\n",
    "\n",
    "\n",
    "## Relational Database Schema\n",
    "There are many schemas that can satisfy these requirements. In this project we will settle with a star-schema to make the queries less demanding in terms of performing joins, but at the cost of normalization, and the possibility of update anomalies. \n",
    "\n",
    "Designing the schema is outside the scope of this project, but if you want to learn more, you would need to study (database normalisation, denormalization and the pros and cons of different approaches towards schema design, such as star schema, snowflake schema, and others). \n",
    "\n",
    "So, our tables will can look like this\n",
    "<center><img src = \"../images/schema.png\" width = 50%> </center>\n",
    "\n",
    "Where,\n",
    "* `user` table holds info about the user `(Dimension Table)`\n",
    "* `song` table holds info about the songs `(Dimension Table)`\n",
    "* `artist` table holds info about the artist `(Dimension Table)`\n",
    "* `time` table just expands info about the timestamp (which hour, day, week, month and year it belongs to) `(Dimension Table)`\n",
    "* `songplay` table logs information whenever a song is played, so it's a `Fact Table`\n",
    "\n",
    "## Which data from which source\n",
    "* The JSON files concerned with `song data` will be used to fill the `song` and `artist` tables\n",
    "* The JSON files concerned with `log data` will be used to fill the `user`, `time` and `songplay` tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(filepath):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_files = get_files(\"../data/song_data/\")\n",
    "df_songs = pd.DataFrame()\n",
    "for path in song_files:\n",
    "    df_current = pd.read_json(path, lines = True)\n",
    "    df_songs = pd.concat([df_songs, df_current])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_songs.num_songs.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_songs</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>duration</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ARD7TVE1187B99BFB1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California - LA</td>\n",
       "      <td>Casual</td>\n",
       "      <td>SOMZWCG12A8C13C480</td>\n",
       "      <td>I Didn't Mean To</td>\n",
       "      <td>218.93179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ARMJAGH1187FB546F3</td>\n",
       "      <td>35.14968</td>\n",
       "      <td>-90.04892</td>\n",
       "      <td>Memphis, TN</td>\n",
       "      <td>The Box Tops</td>\n",
       "      <td>SOCIWDW12A8C13D406</td>\n",
       "      <td>Soul Deep</td>\n",
       "      <td>148.03546</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ARKRRTF1187B9984DA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Sonora Santanera</td>\n",
       "      <td>SOXVLOJ12AB0189215</td>\n",
       "      <td>Amor De Cabaret</td>\n",
       "      <td>177.47546</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AR7G5I41187FB4CE6C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London, England</td>\n",
       "      <td>Adam Ant</td>\n",
       "      <td>SONHOTT12A8C13493C</td>\n",
       "      <td>Something Girls</td>\n",
       "      <td>233.40363</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ARXR32B1187FB57099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Gob</td>\n",
       "      <td>SOFSOCN12A8C143F5D</td>\n",
       "      <td>Face the Ashes</td>\n",
       "      <td>209.60608</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AR8IEZO1187B99055E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Marc Shaiman</td>\n",
       "      <td>SOINLJW12A8C13314C</td>\n",
       "      <td>City Slickers</td>\n",
       "      <td>149.86404</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AR558FS1187FB45658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>40 Grit</td>\n",
       "      <td>SOGDBUF12A8C140FAA</td>\n",
       "      <td>Intro</td>\n",
       "      <td>75.67628</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ARVBRGZ1187FB4675A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Gwen Stefani</td>\n",
       "      <td>SORRZGD12A6310DBC3</td>\n",
       "      <td>Harajuku Girls</td>\n",
       "      <td>290.55955</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ARWB3G61187FB49404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamilton, Ohio</td>\n",
       "      <td>Steve Morse</td>\n",
       "      <td>SODAUVL12A8C13D184</td>\n",
       "      <td>Prognosis</td>\n",
       "      <td>363.85914</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AREVWGE1187B9B890A</td>\n",
       "      <td>-13.44200</td>\n",
       "      <td>-41.99520</td>\n",
       "      <td>Noci (BA)</td>\n",
       "      <td>Bitter End</td>\n",
       "      <td>SOFCHDR12AB01866EF</td>\n",
       "      <td>Living Hell</td>\n",
       "      <td>282.43546</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_songs           artist_id  artist_latitude  artist_longitude  \\\n",
       "0           1  ARD7TVE1187B99BFB1              NaN               NaN   \n",
       "0           1  ARMJAGH1187FB546F3         35.14968         -90.04892   \n",
       "0           1  ARKRRTF1187B9984DA              NaN               NaN   \n",
       "0           1  AR7G5I41187FB4CE6C              NaN               NaN   \n",
       "0           1  ARXR32B1187FB57099              NaN               NaN   \n",
       "..        ...                 ...              ...               ...   \n",
       "0           1  AR8IEZO1187B99055E              NaN               NaN   \n",
       "0           1  AR558FS1187FB45658              NaN               NaN   \n",
       "0           1  ARVBRGZ1187FB4675A              NaN               NaN   \n",
       "0           1  ARWB3G61187FB49404              NaN               NaN   \n",
       "0           1  AREVWGE1187B9B890A        -13.44200         -41.99520   \n",
       "\n",
       "    artist_location       artist_name             song_id             title  \\\n",
       "0   California - LA            Casual  SOMZWCG12A8C13C480  I Didn't Mean To   \n",
       "0       Memphis, TN      The Box Tops  SOCIWDW12A8C13D406         Soul Deep   \n",
       "0                    Sonora Santanera  SOXVLOJ12AB0189215   Amor De Cabaret   \n",
       "0   London, England          Adam Ant  SONHOTT12A8C13493C   Something Girls   \n",
       "0                                 Gob  SOFSOCN12A8C143F5D    Face the Ashes   \n",
       "..              ...               ...                 ...               ...   \n",
       "0                        Marc Shaiman  SOINLJW12A8C13314C     City Slickers   \n",
       "0                             40 Grit  SOGDBUF12A8C140FAA             Intro   \n",
       "0                        Gwen Stefani  SORRZGD12A6310DBC3    Harajuku Girls   \n",
       "0    Hamilton, Ohio       Steve Morse  SODAUVL12A8C13D184         Prognosis   \n",
       "0         Noci (BA)        Bitter End  SOFCHDR12AB01866EF       Living Hell   \n",
       "\n",
       "     duration  year  \n",
       "0   218.93179     0  \n",
       "0   148.03546  1969  \n",
       "0   177.47546     0  \n",
       "0   233.40363  1982  \n",
       "0   209.60608  2007  \n",
       "..        ...   ...  \n",
       "0   149.86404  2008  \n",
       "0    75.67628  2003  \n",
       "0   290.55955  2004  \n",
       "0   363.85914  2000  \n",
       "0   282.43546     0  \n",
       "\n",
       "[71 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pydatabase')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79472d9a3a644261180bada5e9286a6287aa51c02d511d14c058c083b9dd0e71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
